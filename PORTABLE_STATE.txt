# PORTABLE_STATE.txt
Single source of truth for moving/resuming this project.

[Default run]
RUN_NAME=room_v2_context

[Required for training resume]
- configs/paths.yaml
- configs/train.yaml
- configs/gen.yaml
- .env
- data/processed/train.bin
- data/processed/val.bin
- data/processed/train_loss_mask.bin
- data/processed/val_loss_mask.bin
- data/processed/tokenizer.json
- checkpoints/room_v2_context/latest.pt

[Required for inference-only]
- configs/gen.yaml
- .env
- artifacts/model_latest.pt (or model_latest.enc + CHATBOT_MODEL_KEY)

[Environment variables]
- CHATBOT_PASSWORD=...
- CHATBOT_MODEL_KEY=... (enc model only)
- CHATBOT_DEFAULT_USER=... (optional)
- CHATBOT_DEFAULT_BOT=... (optional)

[One-line commands]
- Archive old state:  python -m chatbot.ops archive
- Organize raw txt:   python -m chatbot.ops organize
- Preprocess:         python -m chatbot.ops preprocess
- Train/resume:       python -m chatbot.ops train
- Quick test:         python -m chatbot.ops smoke
- Reply:              python -m chatbot.ops reply "테스트"
- Chat:               python -m chatbot.ops chat
- Bridge dry-run:     python -m chatbot.ops bridge --dry

[Training objective]
- Preprocess builds multi-turn context samples.
- Loss mask marks response span only.
- Trainer uses response-only masked cross-entropy.

[Important]
- If tokenizer/model config changes, resume may be blocked by compatibility checks.
- Keep private data out of git (`data/raw`, `data/processed`, `checkpoints`).
